# -*- coding: utf-8 -*-
"""sentimentAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_JGtsY-F9fXWyL6Pf_rOyuifvtCC7yPl
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize

# Load the Excel file into a pandas DataFrame
df = pd.read_excel('/content/dataset_v2.xlsx')

# Display the first few rows of the DataFrame
display(df)

df['sentiment'] = df['sentiment'].astype(str).str.lower()
df['sentiment'].unique()

dfNeu=df[df['sentiment']=='neutral']

display(dfNeu)

#As input we will have all italian reviews...to test let's detect language and discard non italian ones

!pip install langdetect

from langdetect import detect, DetectorFactory
# Set seed for reproducibility
DetectorFactory.seed = 0

# Define a function to safely detect language
def safe_detect_language(text):
    try:
        return detect(str(text))
    except:
        return np.nan

# Apply the function to the 'review' column
dfNeu['language'] = dfNeu['review'].apply(safe_detect_language)

dfNeu=dfNeu[dfNeu['language']=='it']
display(dfNeu)

!pip install emoji

import re
import emoji
from langdetect import detect


def clean_text(text):

    # normalize spacing
    text = text.strip()
    text = re.sub(r"\s+", " ", text)

    #replace URLs, mentions
    text = re.sub(r"http\S+", "<URL>", text)
    text = re.sub(r"@\w+", "<USER>", text)

    # reduce repeated chars (bello → bello, belloooo → bello)
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)

    return text


def preprocess_for_transformer(text):
    cleaned = clean_text(text)

    encoded = tokenizer(
        cleaned,
        max_length=128,
        truncation=True,
        padding="max_length",
        return_tensors="pt"
    )

    return encoded

dfNeu['cleaned_review'] = dfNeu['review'].apply(clean_text)
display(dfNeu)

from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "MilaNLProc/feel-it-italian-sentiment"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

import re
import emoji
import torch

#-----------------
# 2. Clean Function
# -------------------------
def clean_text(text):

    # Normalize spacing
    text = text.strip()
    text = re.sub(r"\s+", " ", text)

    # Replace URLs and @mentions
    text = re.sub(r"http\S+", "<URL>", text)
    text = re.sub(r"@\w+", "<USER>", text)

    # Normalize repeated characters (belloooo → belloo)
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)

    # Convert emojis to textual tags
    text = emoji.replace_emoji(text, replace=lambda e, data: f" {emoji.demojize(e)} ")

    return text


# -------------------------
# 3. Sentiment Prediction (negative / neutral / positive)
# -------------------------
def predict_sentiment(text):

    cleaned = clean_text(text)

    # Tokenization
    enc = tokenizer(
        cleaned,
        max_length=128,
        truncation=True,
        padding="max_length",
        return_tensors="pt"
    )

    # Model inference
    with torch.no_grad():
        logits = model(**enc).logits
        pred = torch.argmax(logits, dim=1).item()

    # FEEL-IT labels
    labels = ["negative", "neutral", "positive"]
    return labels[pred]

dfNeu["sentiment_pred"] = dfNeu["review"].apply(predict_sentiment)

display(dfNeu)

import re
import emoji
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load multilingual sentiment model (XLM-R)
model_name = "cardiffnlp/twitter-xlm-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
model.eval()

# Cleaning function
def clean_text(text):

    text = text.strip()
    text = re.sub(r"\s+", " ", text)

    # Replace URLs and mentions
    text = re.sub(r"http\S+", "<URL>", text)
    text = re.sub(r"@\w+", "<USER>", text)

    # Reduce repeated characters
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)

    # Emoji → textual representation
    text = emoji.replace_emoji(text, replace=lambda e, data: f" {emoji.demojize(e)} ")

    return text

# Predict sentiment (negative / neutral / positive)
def predict_sentimentMult(text):

    cleaned = clean_text(text)

    # Tokenization
    enc = tokenizer(
        cleaned,
        max_length=128,
        truncation=True,
        padding="max_length",
        return_tensors="pt"
    )

    with torch.no_grad():
        logits = model(**enc).logits
        pred = torch.argmax(logits, dim=1).item()

    labels = ["negative", "neutral", "positive"]
    return labels[pred]

dfNeu["sentiment_predMulti"] = dfNeu["review"].apply(predict_sentimentMult)

display(dfNeu)

from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model="MilaNLProc/feel-it-italian-sentiment",
    top_k=None
)

dfNeu["sentiment_predScore"] = dfNeu["review"].apply(classifier)

dfNeu["sentiment_predScoreNumber"] =dfNeu["sentiment_predScore"].apply(lambda x: x[0][0]["score"])
dfNeu["sentiment_predScoreLabel"] =dfNeu["sentiment_predScore"].apply(lambda x: x[0][0]["label"])

display(dfNeu)

# Mapping sentiment → numero
mapping = {"negative": -1, "neutral": 0, "positive": 1}

# Convert columns
dfNeu["v1"] = dfNeu["sentiment_pred"].map(mapping)
dfNeu["v2"] = dfNeu["sentiment_predMulti"].map(mapping)
dfNeu["v3"] = dfNeu["sentiment_predScoreLabel"].map(mapping)

# Composition score
dfNeu["sentiment_composition"] = dfNeu["v1"] + dfNeu["v2"] + dfNeu["v3"]

# Optional: final sentiment from numeric
def convert_numeric_to_label(val):
    if val > 0:
        return "positive"
    elif val <= 0:
        return "negative"


dfNeu["sentiment_final_numeric"] = dfNeu["sentiment_composition"].apply(convert_numeric_to_label)

display(dfNeu[['review', 'sentiment', 'sentiment_final_numeric']])

from google.colab import files
dfNeu.to_excel("dataFramNewNeutral.xlsx", index=True)
files.download("dataFramNewNeutral.xlsx")

import emoji
import re

# funzione per estrarre emoji da un testo
def extract_emojis(text):
    # emoji.emoji_list() returns a list of dicts, each with 'emoji' key
    return [item['emoji'] for item in emoji.emoji_list(str(text))]

# Filtra solo le review neutrali
df_neutral = df[df["sentiment"] == "neutral"].copy()

# Estrae le emoji per ogni review
df_neutral["emoji_list"] = df_neutral["review"].apply(lambda x: extract_emojis(str(x)))

# Conta quante emoji sono presenti per riga
df_neutral["emoji_count"] = df_neutral["emoji_list"].apply(len)

# Totale emoji nelle review neutrali
total_emojis = df_neutral["emoji_count"].sum()

print("Totale emoji nelle review neutrali:", total_emojis)

# Mostra le prime righe del risultato
display(df_neutral[["review", "emoji_list", "emoji_count"]])

"""---

✔ FEEL-IT (pipeline)

✔ FEEL-IT (tokenizer + model)

✔ XLM-RoBERTa (tokenizer + model)
"""